# ETL RadioQ Data Pipeline

End-to-end ETL (Extract, Transform, Load) pipeline project for RadioQ data, built as a Data Engineering portfolio project.  
This pipeline processes multiple Excel-based datasets and loads clean, structured data into a PostgreSQL database (Supabase).

---

## ğŸ“Œ Overview

This project implements a modular ETL architecture to handle RadioQ operational data, including:

- **Airtime data** (jam tayang siaran)
- **Advertising orders data**
- **Listener survey data**

Each dataset is processed through a dedicated ETL pipeline and orchestrated centrally for maintainability and scalability.

---

## ğŸ›  Tech Stack

- **Language**: Python
- **Data Processing**: Pandas
- **Database**: PostgreSQL (Supabase)
- **Architecture**: Modular ETL + Orchestrator Pattern
- **Version Control**: Git & GitHub

---

## ğŸ“‚ Data Sources

All data sources are stored as Excel files:

- `Data_Radio_q.xlsx`
  - Airtime sheets (e.g. `JAM TAYANG 2018`)
  - Orders sheets (e.g. `ORDER IKLAN 2020`)
  - Survey sheets (e.g. `DATA RESPON PENDENGAR 2022`)

Sheet selection is handled dynamically using **regex-based extraction**.

---

## ğŸ— ETL Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Excel Files â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extract Layer â”‚
â”‚ (Regex-based) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transform Layer â”‚
â”‚ - Cleaning â”‚
â”‚ - Normalization â”‚
â”‚ - Deduplication â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Layer â”‚
â”‚ PostgreSQL â”‚
â”‚ (Supabase) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
## ğŸ“ Project Structure

radioq_etl_big/
â”œâ”€â”€ config/
â”‚ â””â”€â”€ db_config.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â””â”€â”€ processed/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ etl_airtimes/
â”‚ â”‚ â”œâ”€â”€ extract.py
â”‚ â”‚ â”œâ”€â”€ transform.py
â”‚ â”‚ â””â”€â”€ load.py
â”‚ â”œâ”€â”€ etl_orders/
â”‚ â”‚ â”œâ”€â”€ extract.py
â”‚ â”‚ â”œâ”€â”€ transform.py
â”‚ â”‚ â””â”€â”€ load.py
â”‚ â”œâ”€â”€ etl_surveys/
â”‚ â”‚ â”œâ”€â”€ extract.py
â”‚ â”‚ â”œâ”€â”€ transform.py
â”‚ â”‚ â””â”€â”€ load.py
â”‚ â””â”€â”€ orchestrator.py
â”œâ”€â”€ main.py
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ How to Run

### 1. Clone Repository
```bash
git clone https://github.com/Mariimo/etl-radioQ.git
cd etl-radioQ

2. Install Dependencies
pip install pandas sqlalchemy psycopg2

3. Configure Database

Update database connection in:

config/db_config.py

DB_URL = "postgresql://user:password@host:port/database"

4. Run ETL Pipeline
python main.py

ğŸš€ Pipeline Execution

By default, main.py runs:

Airtime ETL

Orders ETL

Surveys ETL

Each pipeline logs:

Extracted rows

Transformed rows

Load status

ğŸ—„ Database Tables

The pipeline creates and loads data into:

airtimes

orders

surveys

All tables are stored in PostgreSQL (Supabase).

âœ… Key Features

Regex-based dynamic sheet extraction

Modular ETL design

Centralized orchestration

Production-ready project structure

Suitable for Data Engineer portfolio

ğŸ“ˆ Future Improvements

Add logging & monitoring

Schedule with Apache Airflow

Add data quality checks

Implement incremental loading

ğŸ‘¤ Author

Mariimo
Data Engineer Portfolio Project